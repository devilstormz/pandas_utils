import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

class CollateralSwapMatcher:
    """
    Matching engine to identify collateral swaps from Bond Borrow/Lend and Repo/Reverse Repo trades
    """
    
    def __init__(self, tolerance_days: int = 3, notional_tolerance: float = 0.05):
        """
        Initialize the matching engine
        
        Args:
            tolerance_days: Maximum days difference for maturity matching
            notional_tolerance: Relative tolerance for notional matching (5% default)
        """
        self.tolerance_days = tolerance_days
        self.notional_tolerance = notional_tolerance
        
        # Product hierarchy (higher number = higher quality)
        self.product_hierarchy = {
            'GOVT': 3,
            'CORP': 2, 
            'ABS': 1,
            'OTHER': 0
        }
        
        # Rating hierarchy (higher number = higher quality)
        self.rating_hierarchy = {
            'AAA': 10, 'AA+': 9, 'AA': 8, 'AA-': 7,
            'A+': 6, 'A': 5, 'A-': 4,
            'BBB+': 3, 'BBB': 2, 'BBB-': 1,
            'BB+': 0, 'BB': -1, 'BB-': -2,
            'B+': -3, 'B': -4, 'B-': -5,
            'CCC+': -6, 'CCC': -7, 'CCC-': -8,
            'CC': -9, 'C': -10, 'D': -11,
            'NR': -12  # Not Rated
        }
    
    def _normalize_product_type(self, product_type: str) -> str:
        """Normalize product type to standard categories"""
        if pd.isna(product_type):
            return 'OTHER'
        
        product_upper = str(product_type).upper()
        if 'GOVT' in product_upper or 'GOV' in product_upper or 'TREASURY' in product_upper:
            return 'GOVT'
        elif 'CORP' in product_upper or 'CORPORATE' in product_upper:
            return 'CORP'
        elif 'ABS' in product_upper or 'ASSET' in product_upper:
            return 'ABS'
        else:
            return 'OTHER'
    
    def _normalize_rating(self, rating: str) -> str:
        """Normalize rating to standard format"""
        if pd.isna(rating):
            return 'NR'
        
        rating_clean = str(rating).upper().strip()
        if rating_clean in self.rating_hierarchy:
            return rating_clean
        else:
            return 'NR'
    
    def _get_quality_score(self, product_type: str, rating: str) -> float:
        """Calculate overall quality score combining product hierarchy and rating"""
        product_score = self.product_hierarchy.get(product_type, 0)
        rating_score = self.rating_hierarchy.get(rating, -12)
        
        # Weight product type more heavily than rating
        return product_score * 10 + rating_score
    
    def _is_matching_pair(self, trade1: pd.Series, trade2: pd.Series) -> bool:
        """
        Check if two trades form a matching collateral swap pair
        """
        # Must be opposite trade types
        trade_types = {trade1['trade_type'], trade2['trade_type']}
        valid_pairs = [
            {'BOND_BORROW', 'BOND_LEND'},
            {'REPO', 'REVERSE_REPO'}
        ]
        
        if not any(trade_types == set(pair) for pair in valid_pairs):
            return False
        
        # Same counterparty
        if trade1['counterparty'] != trade2['counterparty']:
            return False
        
        # Notional matching (within tolerance)
        notional_diff = abs(trade1['notional'] - trade2['notional']) / max(trade1['notional'], trade2['notional'])
        if notional_diff > self.notional_tolerance:
            return False
        
        # Maturity matching (within tolerance)
        maturity_diff = abs((pd.to_datetime(trade1['maturity_date']) - 
                           pd.to_datetime(trade2['maturity_date'])).days)
        if maturity_diff > self.tolerance_days:
            return False
        
        # Same trade date (typically same day execution)
        if trade1['trade_date'] != trade2['trade_date']:
            return False
        
        return True
    
    def _determine_swap_type(self, trade1: pd.Series, trade2: pd.Series) -> str:
        """
        Determine if the collateral swap is an upgrade, downgrade, or neutral
        (Simplified as data is already normalized)
        """
        # Get quality scores for both securities (using original columns since data is normalized)
        quality1 = self._get_quality_score(trade1['product_type'], trade1['rating'])
        quality2 = self._get_quality_score(trade2['product_type'], trade2['rating'])
        
        # Determine which trade is giving vs receiving
        if trade1['trade_type'] in ['BOND_BORROW', 'REPO']:
            # trade1 is receiving collateral, trade2 is giving collateral
            receiving_quality = quality1
            giving_quality = quality2
        else:
            # trade1 is giving collateral, trade2 is receiving collateral
            receiving_quality = quality2
            giving_quality = quality1
        
        quality_diff = receiving_quality - giving_quality
        
        if quality_diff > 0:
            return 'UPGRADE'
        elif quality_diff < 0:
            return 'DOWNGRADE'
        else:
            return 'NEUTRAL'
    
    def preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Preprocess the trade dataframe (simplified as data is already normalized)
        """
        df_processed = df.copy()
        
        # Ensure required columns exist
        required_cols = ['trade_id', 'trade_type', 'counterparty', 'notional', 
                        'maturity_date', 'trade_date', 'product_type', 'rating']
        
        missing_cols = [col for col in required_cols if col not in df_processed.columns]
        if missing_cols:
            raise ValueError(f"Missing required columns: {missing_cols}")
        
        # Convert dates (if they're not already datetime)
        if not pd.api.types.is_datetime64_any_dtype(df_processed['trade_date']):
            df_processed['trade_date'] = pd.to_datetime(df_processed['trade_date'])
        if not pd.api.types.is_datetime64_any_dtype(df_processed['maturity_date']):
            df_processed['maturity_date'] = pd.to_datetime(df_processed['maturity_date'])
        
        # Initialize swap tracking columns
        df_processed['is_collateral_swap'] = False
        df_processed['swap_pair_id'] = None
        df_processed['swap_type'] = None
        df_processed['matched_trade_id'] = None
        df_processed['swap_trade_ids'] = None  # New column for trade IDs in swap
        
        return df_processed
    
    def find_collateral_swaps(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Main method to find collateral swaps in the dataset
        """
        df_processed = self.preprocess_data(df)
        
        # Sort by trade_date and counterparty for efficient matching
        df_sorted = df_processed.sort_values(['trade_date', 'counterparty']).reset_index(drop=True)
        
        matched_indices = set()
        swap_pair_counter = 0
        
        print(f"Processing {len(df_sorted)} trades for collateral swap matching...")
        
        # Iterate through trades to find matches
        for i in range(len(df_sorted)):
            if i in matched_indices:
                continue
                
            trade1 = df_sorted.iloc[i]
            
            # Look for potential matches in subsequent trades
            # Limit search to same day and nearby trades for efficiency
            search_end = min(i + 100, len(df_sorted))  
            
            for j in range(i + 1, search_end):
                if j in matched_indices:
                    continue
                    
                trade2 = df_sorted.iloc[j]
                
                # Skip if different trade date (optimization)
                if trade1['trade_date'] != trade2['trade_date']:
                    continue
                
                if self._is_matching_pair(trade1, trade2):
                    # Found a matching pair!
                    swap_pair_counter += 1
                    swap_type = self._determine_swap_type(trade1, trade2)
                    swap_trade_ids = f"{trade1['trade_id']},{trade2['trade_id']}"
                    
                    # Update both trades
                    df_sorted.at[i, 'is_collateral_swap'] = True
                    df_sorted.at[i, 'swap_pair_id'] = f'SWAP_{swap_pair_counter:06d}'
                    df_sorted.at[i, 'swap_type'] = swap_type
                    df_sorted.at[i, 'matched_trade_id'] = trade2['trade_id']
                    df_sorted.at[i, 'swap_trade_ids'] = swap_trade_ids
                    
                    df_sorted.at[j, 'is_collateral_swap'] = True
                    df_sorted.at[j, 'swap_pair_id'] = f'SWAP_{swap_pair_counter:06d}'
                    df_sorted.at[j, 'swap_type'] = swap_type
                    df_sorted.at[j, 'matched_trade_id'] = trade1['trade_id']
                    df_sorted.at[j, 'swap_trade_ids'] = swap_trade_ids
                    
                    matched_indices.add(i)
                    matched_indices.add(j)
                    break
        
        # Sort back to original order if needed
        result_df = df_sorted.sort_values('trade_id').reset_index(drop=True)
        
        return result_df
    
    def get_swap_summary(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Generate summary statistics of identified collateral swaps
        """
        swap_trades = df[df['is_collateral_swap'] == True].copy()
        
        if len(swap_trades) == 0:
            return pd.DataFrame()
        
        # Group by swap pair
        summary_data = []
        
        for swap_id in swap_trades['swap_pair_id'].unique():
            pair_trades = swap_trades[swap_trades['swap_pair_id'] == swap_id]
            
            if len(pair_trades) == 2:
                trade1, trade2 = pair_trades.iloc[0], pair_trades.iloc[1]
                
                summary_data.append({
                    'swap_pair_id': swap_id,
                    'swap_type': trade1['swap_type'],
                    'trade_date': trade1['trade_date'],
                    'counterparty': trade1['counterparty'],
                    'notional': trade1['notional'],
                    'maturity_date': trade1['maturity_date'],
                    'trade1_id': trade1['trade_id'],
                    'trade1_type': trade1['trade_type'],
                    'trade1_product': trade1['product_type'],
                    'trade1_rating': trade1['rating'],
                    'trade2_id': trade2['trade_id'],
                    'trade2_type': trade2['trade_type'],
                    'trade2_product': trade2['product_type'],
                    'trade2_rating': trade2['rating']
                })
        
        return pd.DataFrame(summary_data)
    
    def join_to_original(self, original_df: pd.DataFrame, processed_df: pd.DataFrame) -> pd.DataFrame:
        """
        Join the swap results back to the original dataframe maintaining original length
        
        Args:
            original_df: Original trade dataframe
            processed_df: Processed dataframe with swap identification
            
        Returns:
            DataFrame with same length as original with swap columns added
        """
        # Select only the swap-related columns from processed dataframe
        swap_columns = ['trade_id', 'is_collateral_swap', 'swap_pair_id', 'swap_type', 
                       'matched_trade_id', 'swap_trade_ids']
        
        swap_info = processed_df[swap_columns].copy()
        
        # Perform left join to maintain original dataframe length
        result_df = original_df.merge(swap_info, on='trade_id', how='left')
        
        # Fill NaN values for non-swap trades
        result_df['is_collateral_swap'] = result_df['is_collateral_swap'].fillna(False)
        result_df['swap_pair_id'] = result_df['swap_pair_id'].fillna('')
        result_df['swap_type'] = result_df['swap_type'].fillna('')
        result_df['matched_trade_id'] = result_df['matched_trade_id'].fillna('')
        result_df['swap_trade_ids'] = result_df['swap_trade_ids'].fillna('')
        
        return result_df


# Example usage and testing
def create_sample_data():
    """Create sample trade data for testing"""
    np.random.seed(42)
    
    sample_data = []
    base_date = datetime(2024, 1, 15)
    
    # Create some matching pairs
    for i in range(50):
        counterparty = f"CP_{np.random.randint(1, 11):02d}"
        notional = np.random.randint(1, 100) * 1000000  # 1M to 100M
        trade_date = base_date + timedelta(days=np.random.randint(0, 30))
        maturity_date = trade_date + timedelta(days=np.random.randint(30, 365))
        
        product_types = ['GOVT', 'CORP', 'ABS']
        ratings = ['AAA', 'AA', 'A', 'BBB', 'BB', 'B']
        
        # Create matching pair
        if np.random.random() < 0.6:  # 60% chance of creating a pair
            # Bond Borrow/Lend pair
            trade1_type = 'BOND_BORROW'
            trade2_type = 'BOND_LEND'
            
            sample_data.append({
                'trade_id': f'T{len(sample_data)+1:06d}',
                'trade_type': trade1_type,
                'counterparty': counterparty,
                'notional': notional,
                'trade_date': trade_date,
                'maturity_date': maturity_date,
                'product_type': np.random.choice(product_types),
                'rating': np.random.choice(ratings)
            })
            
            sample_data.append({
                'trade_id': f'T{len(sample_data)+1:06d}',
                'trade_type': trade2_type,
                'counterparty': counterparty,
                'notional': notional * (1 + np.random.uniform(-0.02, 0.02)),  # Small variation
                'trade_date': trade_date,
                'maturity_date': maturity_date + timedelta(days=np.random.randint(-2, 3)),
                'product_type': np.random.choice(product_types),
                'rating': np.random.choice(ratings)
            })
        else:
            # Single trade
            trade_types = ['BOND_BORROW', 'BOND_LEND', 'REPO', 'REVERSE_REPO']
            sample_data.append({
                'trade_id': f'T{len(sample_data)+1:06d}',
                'trade_type': np.random.choice(trade_types),
                'counterparty': counterparty,
                'notional': notional,
                'trade_date': trade_date,
                'maturity_date': maturity_date,
                'product_type': np.random.choice(product_types),
                'rating': np.random.choice(ratings)
            })
    
    return pd.DataFrame(sample_data)


# Example usage
if __name__ == "__main__":
    # Create sample data
    print("Creating sample trade data...")
    sample_df = create_sample_data()
    original_df = sample_df.copy()  # Keep original for joining back
    print(f"Created {len(sample_df)} sample trades")
    
    # Print sample data
    print("\n" + "="*80)
    print("SAMPLE TRADE DATA:")
    print("="*80)
    print(sample_df.to_string(index=False))
    print("\n" + "="*80)
    
    # Initialize matching engine
    matcher = CollateralSwapMatcher(tolerance_days=3, notional_tolerance=0.05)
    
    # Find collateral swaps
    print("\nFinding collateral swaps...")
    result_df = matcher.find_collateral_swaps(sample_df)
    
    # Display results
    swap_count = result_df['is_collateral_swap'].sum()
    print(f"\nFound {swap_count} trades that are part of collateral swaps")
    print(f"Number of swap pairs: {swap_count // 2}")
    
    # Show swap type distribution
    if swap_count > 0:
        swap_types = result_df[result_df['is_collateral_swap']]['swap_type'].value_counts()
        print(f"\nSwap type distribution:")
        for swap_type, count in swap_types.items():
            print(f"  {swap_type}: {count // 2} pairs")
    
    # Show collateral swap trades
    if swap_count > 0:
        print(f"\n" + "="*120)
        print("IDENTIFIED COLLATERAL SWAPS:")
        print("="*120)
        swap_trades = result_df[result_df['is_collateral_swap']].copy()
        swap_trades = swap_trades.sort_values('swap_pair_id')
        
        display_cols = ['trade_id', 'trade_type', 'counterparty', 'notional', 'product_type', 
                       'rating', 'swap_pair_id', 'swap_type', 'matched_trade_id', 'swap_trade_ids']
        print(swap_trades[display_cols].to_string(index=False))
        print("="*120)
    
    # Generate summary
    summary_df = matcher.get_swap_summary(result_df)
    if len(summary_df) > 0:
        print(f"\nCOLLATERAL SWAP SUMMARY:")
        print("-"*100)
        summary_display = summary_df[['swap_pair_id', 'swap_type', 'counterparty', 'notional', 
                                    'trade1_id', 'trade1_product', 'trade1_rating', 
                                    'trade2_id', 'trade2_product', 'trade2_rating']]
        print(summary_display.to_string(index=False))
    
    print(f"\nProcessed dataframe shape: {result_df.shape}")
    print("Columns added: is_collateral_swap, swap_pair_id, swap_type, matched_trade_id, swap_trade_ids")
    
    # NEW: Join back to original dataframe maintaining original length
    print(f"\n" + "="*80)
    print("JOINING RESULTS TO ORIGINAL DATAFRAME:")
    print("="*80)
    
    # Create the joined dataframe
    original_with_swaps = matcher.join_to_original(original_df, result_df)
    
    print(f"Original dataframe shape: {original_df.shape}")
    print(f"Joined dataframe shape: {original_with_swaps.shape}")
    print(f"Length maintained: {len(original_df) == len(original_with_swaps)}")
    
    # Show sample of joined data
    print(f"\nSample of joined dataframe (first 10 rows):")
    print("-"*120)
    join_display_cols = ['trade_id', 'trade_type', 'counterparty', 'notional', 'product_type', 
                        'rating', 'is_collateral_swap', 'swap_pair_id', 'swap_type']
    print(original_with_swaps[join_display_cols].head(10).to_string(index=False))
    
    # Show statistics of joined data
    swap_count_joined = original_with_swaps['is_collateral_swap'].sum()
    non_swap_count = len(original_with_swaps) - swap_count_joined
    
    print(f"\nJoined dataframe statistics:")
    print(f"  Total trades: {len(original_with_swaps)}")
    print(f"  Collateral swap trades: {swap_count_joined}")
    print(f"  Non-swap trades: {non_swap_count}")
    print(f"  Swap pairs: {swap_count_joined // 2}")
    
    if swap_count_joined > 0:
        print(f"\nSwap types in joined dataframe:")
        swap_types_joined = original_with_swaps[original_with_swaps['is_collateral_swap']]['swap_type'].value_counts()
        for swap_type, count in swap_types_joined.items():
            print(f"  {swap_type}: {count // 2} pairs")
    
    print(f"\n" + "="*80)
    print("SUMMARY:")
    print("="*80)
    print(f"result_df: Processed dataframe with swap identification ({result_df.shape})")
    print(f"original_with_swaps: Original dataframe with swap columns joined ({original_with_swaps.shape})")
    print(f"summary_df: Summary of identified swaps ({summary_df.shape if len(summary_df) > 0 else 'No swaps found'})")
    print("="*80)
